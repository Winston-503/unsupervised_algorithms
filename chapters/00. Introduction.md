## Introduction

*Unsupervised learning* is a machine learning technique in which developers don't need to supervise the model. Instead, this type of learning allows the model to work independently *without any supervision* to discover hidden patterns and information that was previously undetected (since data is not labeled). It mainly deals with the unlabeled data, while supervised learning, as we remember, deals with labeled data.

| ![supervised_vs_unsupervised.jpg](../img/supervised_vs_unsupervised.jpg) |
|:--:|
| <b>Supervised vs Unsupervised Learning. [Public Domain](https://commons.wikimedia.org/wiki/File:Machin_learning.png)</b>|

The most popular unsupervised learning tasks are:
- **Dimensionality Reduction** - the task of reducing the number of input features in a dataset,
- **Anomaly Detection** - the task of detecting instances that are very different from the norm, and
- **Clustering** - the task of grouping similar instances into clusters.

The *Clustering* task is probably the most important in unsupervised learning since it has a wide variety of applications. At the same time *Dimensionality Reduction* and *Anomaly Detection* tasks can be attributed to auxiliary ones (they are often interpreted as *data cleaning* or *feature engineering* tools). Despite the fact that these tasks are definitely important, some people often do not distinguish them separately when studying unsupervised learning, leaving only the clustering task.   

Algorithms for solving these tasks and that we will mention in this article are:
- *Dimensionality Reduction*:
  - *Principal Component Analysis*;
  - *Manifold Learning* - *LLE*, *Isomap*, *t-SNE*;
  - *Autoencoders* and others.
- *Anomaly Detection*:
  - *Isolation Forest*;
  - *Local Outlier Factor*;
  - *Minimum Covariance Determinant* and other algorithms initially designed for dimensionality reduction or supervised learning.
- *Clustering*:
  - *K-Means*;
  - *Hierarchical Clustering* and *Spectral Clustering*;
  - *Gaussian Mixture Models*;
  - *DBSCAN*, *BIRCH*, and others.
