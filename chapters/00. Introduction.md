## Introduction

*Unsupervised learning* is a machine learning technique in which the users do not need to supervise the model. Instead, it allows the model to work on its own to discover patterns and information that was previously undetected. It mainly deals with the unlabelled data.

| ![supervised_vs_unsupervised.jpg](../img/supervised_vs_unsupervised.jpg) |
|:--:|
| <b>Supervised vs Unsupervised Learning. [Public Domain](https://commons.wikimedia.org/wiki/File:Machin_learning.png)</b>|

The most popular unsupervised learning tasks and algorithms for solving them are:
- **Dimensionality Reduction** - task of reducing the number of input features in a dataset:
  - *PCA*
  - *Manifold Learning* - *LLE*, *Isomap*, *t-SNE*
  - *Autoencoders* and others
- **Anomaly Detection** - the task of detecting instances that are very different from the norm:
  - *Isolation Forest*
  - *Local Outlier Factor*
  - *Minimum Covariance Determinant*
  - other algorithms
- **Clustering** - task of grouping simular instances into clusters:
  - *K-Means*
  - *Hierarchical Clustering*
  - *DBSCAN* and *OPTICS*
  - *Affinity Propagation*
  - *Mean Shift*
  - *BIRCH*
  - *Gaussian Mixture Models*

The *Clustering* task is probably the most important in unsupervised learning, since it has many applications. At the same time *Dimensionality Reduction* and *Anomaly Detection* tasks can be attributed to auxiliary ones (they are often interpreted as *data cleaning* or *feature engineering* tools). Despite the fact that these tasks are definitely important, some people often do not distinguish them separately when studying unsupervised learning, leaving only the clustering task. 